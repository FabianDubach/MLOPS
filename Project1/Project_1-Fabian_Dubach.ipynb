{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRH0teWHl4Uy"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "*(Note: This notebook runs significantly faster if you have access to a GPU. Use either the GPUHub, Google Colab, or your own GPU.)*\n",
        "\n",
        "In this project, you will optimize the hyperparameters of a model in 3 stages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCjw5BfeX3O4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BWNKzfGl4U2"
      },
      "source": [
        "## Paraphrase Detection\n",
        "We finetune [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) on [MRPC](https://huggingface.co/datasets/glue/viewer/mrpc/train), a paraphrase detection dataset. This notebook is adapted from a [PyTorch Lightning example](https://lightning.ai/docs/pytorch/1.9.5/notebooks/lightning_examples/text-transformers.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3PUFAq9l4U2"
      },
      "outputs": [],
      "source": [
        "%pip install -q torch transformers lightning datasets wandb evaluate ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sceF_eD1l4U4"
      },
      "source": [
        "The next 4 cells are:\n",
        "* Imports\n",
        "* The `GLUEDataModule` loads the task's dataset and creates dataloaders for the train and valid sets.\n",
        "* The `GLUETransformer` implements the model forward pass and the training/validation steps. You can check here what is logged with the `self.log` calls.\n",
        "* The last cell runs training with the given parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v73k3e6el4U4"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "\n",
        "import wandb\n",
        "import datasets\n",
        "import evaluate\n",
        "import lightning as L\n",
        "import torch\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Y8uENxF9i4"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y7SVy51l4U4"
      },
      "outputs": [],
      "source": [
        "class GLUEDataModule(L.LightningDataModule):\n",
        "    task_text_field_map = {\n",
        "        \"cola\": [\"sentence\"],\n",
        "        \"sst2\": [\"sentence\"],\n",
        "        \"mrpc\": [\"sentence1\", \"sentence2\"],\n",
        "        \"qqp\": [\"question1\", \"question2\"],\n",
        "        \"stsb\": [\"sentence1\", \"sentence2\"],\n",
        "        \"mnli\": [\"premise\", \"hypothesis\"],\n",
        "        \"qnli\": [\"question\", \"sentence\"],\n",
        "        \"rte\": [\"sentence1\", \"sentence2\"],\n",
        "        \"wnli\": [\"sentence1\", \"sentence2\"],\n",
        "        \"ax\": [\"premise\", \"hypothesis\"],\n",
        "    }\n",
        "\n",
        "    glue_task_num_labels = {\n",
        "        \"cola\": 2,\n",
        "        \"sst2\": 2,\n",
        "        \"mrpc\": 2,\n",
        "        \"qqp\": 2,\n",
        "        \"stsb\": 1,\n",
        "        \"mnli\": 3,\n",
        "        \"qnli\": 2,\n",
        "        \"rte\": 2,\n",
        "        \"wnli\": 2,\n",
        "        \"ax\": 3,\n",
        "    }\n",
        "\n",
        "    loader_columns = [\n",
        "        \"datasets_idx\",\n",
        "        \"input_ids\",\n",
        "        \"token_type_ids\",\n",
        "        \"attention_mask\",\n",
        "        \"start_positions\",\n",
        "        \"end_positions\",\n",
        "        \"labels\",\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name_or_path: str,\n",
        "        task_name: str = \"mrpc\",\n",
        "        max_seq_length: int = 128,\n",
        "        train_batch_size: int = 32,\n",
        "        eval_batch_size: int = 32,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model_name_or_path = model_name_or_path\n",
        "        self.task_name = task_name\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "\n",
        "        self.text_fields = self.task_text_field_map[task_name]\n",
        "        self.num_labels = self.glue_task_num_labels[task_name]\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, use_fast=True)\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        self.dataset = datasets.load_dataset(\"glue\", self.task_name)\n",
        "\n",
        "        for split in self.dataset.keys():\n",
        "            self.dataset[split] = self.dataset[split].map(\n",
        "                self.convert_to_features,\n",
        "                batched=True,\n",
        "                remove_columns=[\"label\"],\n",
        "            )\n",
        "            self.columns = [c for c in self.dataset[split].column_names if c in self.loader_columns]\n",
        "            self.dataset[split].set_format(type=\"torch\", columns=self.columns)\n",
        "\n",
        "        self.eval_splits = [x for x in self.dataset.keys() if \"validation\" in x]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        datasets.load_dataset(\"glue\", self.task_name)\n",
        "        AutoTokenizer.from_pretrained(self.model_name_or_path, use_fast=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"train\"], batch_size=self.train_batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        if len(self.eval_splits) == 1:\n",
        "            return DataLoader(self.dataset[\"validation\"], batch_size=self.eval_batch_size)\n",
        "        elif len(self.eval_splits) > 1:\n",
        "            return [DataLoader(self.dataset[x], batch_size=self.eval_batch_size) for x in self.eval_splits]\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        if len(self.eval_splits) == 1:\n",
        "            return DataLoader(self.dataset[\"test\"], batch_size=self.eval_batch_size)\n",
        "        elif len(self.eval_splits) > 1:\n",
        "            return [DataLoader(self.dataset[x], batch_size=self.eval_batch_size) for x in self.eval_splits]\n",
        "\n",
        "    def convert_to_features(self, example_batch, indices=None):\n",
        "        # Either encode single sentence or sentence pairs\n",
        "        if len(self.text_fields) > 1:\n",
        "            texts_or_text_pairs = list(zip(example_batch[self.text_fields[0]], example_batch[self.text_fields[1]]))\n",
        "        else:\n",
        "            texts_or_text_pairs = example_batch[self.text_fields[0]]\n",
        "\n",
        "        # Tokenize the text/text pairs\n",
        "        features = self.tokenizer.batch_encode_plus(\n",
        "            texts_or_text_pairs, max_length=self.max_seq_length, padding=\"max_length\", truncation=True\n",
        "        )\n",
        "\n",
        "        # Rename label to labels to make it easier to pass to model forward\n",
        "        features[\"labels\"] = example_batch[\"label\"]\n",
        "\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUz79kqnDgUM"
      },
      "outputs": [],
      "source": [
        "learning_rate: float = 2e-5  # Range: 1e-5 to 5e-5 (log scale)\n",
        "weight_decay: float = 0.01  # Range: 0.0 to 0.1\n",
        "adam_epsilon: float = 1e-8  # Range: 1e-9 to 1e-7 (log scale)\n",
        "train_batch_size: int = 32  # Keep fixed for consistent comparison\n",
        "eval_batch_size: int = 32  # Keep fixed for consistent comparison\n",
        "warmup_steps: int = 100  # Range: 0 to 500\n",
        "dropout_rate: float = 0.1  # Range: 0.0 to 0.3\n",
        "max_seq_length: int = 256  # Options: 64, 128, 256\n",
        "gradient_clip_val: float = 1.0  # Range: 0.5 to 2.0\n",
        "num_epochs: int = 3 # Fixed parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLVufemTl4U5"
      },
      "outputs": [],
      "source": [
        "class GLUETransformer(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name_or_path: str,\n",
        "        num_labels: int,\n",
        "        task_name: str,\n",
        "        learning_rate: float = learning_rate,\n",
        "        warmup_steps: int = warmup_steps,\n",
        "        weight_decay: float = weight_decay,\n",
        "        adam_epsilon: float = adam_epsilon,\n",
        "        dropout_rate: float = dropout_rate,\n",
        "        train_batch_size: int = train_batch_size,\n",
        "        eval_batch_size: int = eval_batch_size,\n",
        "        eval_splits: Optional[list] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Load config and set dropout\n",
        "        self.config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
        "        self.config.attention_probs_dropout_prob = dropout_rate\n",
        "        self.config.hidden_dropout_prob = dropout_rate\n",
        "\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, config=self.config)\n",
        "        self.metric = evaluate.load(\n",
        "            \"glue\", self.hparams.task_name, experiment_id=datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "        )\n",
        "\n",
        "        self.validation_step_outputs = []\n",
        "        self.training_step_outputs = []\n",
        "\n",
        "        # Track best validation accuracy\n",
        "        self.best_val_accuracy = 0.0\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        return self.model(**inputs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Calculate predictions for accuracy\n",
        "        if self.hparams.num_labels > 1:\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "        elif self.hparams.num_labels == 1:\n",
        "            preds = logits.squeeze()\n",
        "\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Store outputs for epoch-end calculation\n",
        "        self.training_step_outputs.append({\"loss\": loss, \"preds\": preds, \"labels\": labels})\n",
        "\n",
        "        # Log loss for each step\n",
        "        self.log(\"train_loss_step\", loss, prog_bar=False, on_step=True, on_epoch=False)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Calculate average training loss\n",
        "        avg_loss = torch.stack([x[\"loss\"] for x in self.training_step_outputs]).mean()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        preds = torch.cat([x[\"preds\"] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
        "        labels = torch.cat([x[\"labels\"] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
        "\n",
        "        train_metrics = self.metric.compute(predictions=preds, references=labels)\n",
        "        train_accuracy = train_metrics.get('accuracy', train_metrics.get('f1', 0.0))\n",
        "\n",
        "        # Log training metrics\n",
        "        self.log(\"train_loss\", avg_loss, prog_bar=True, on_epoch=True)\n",
        "        self.log(\"train_accuracy\", train_accuracy, prog_bar=True, on_epoch=True)\n",
        "\n",
        "        # Clear outputs\n",
        "        self.training_step_outputs.clear()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        outputs = self(**batch)\n",
        "        val_loss, logits = outputs[:2]\n",
        "\n",
        "        if self.hparams.num_labels > 1:\n",
        "            preds = torch.argmax(logits, axis=1)\n",
        "        elif self.hparams.num_labels == 1:\n",
        "            preds = logits.squeeze()\n",
        "\n",
        "        labels = batch[\"labels\"]\n",
        "        self.validation_step_outputs.append({\"loss\": val_loss, \"preds\": preds, \"labels\": labels})\n",
        "        return val_loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        if self.hparams.task_name == \"mnli\":\n",
        "            for i, output in enumerate(self.validation_step_outputs):\n",
        "                # matched or mismatched\n",
        "                split = self.hparams.eval_splits[i].split(\"_\")[-1]\n",
        "                preds = torch.cat([x[\"preds\"] for x in output]).detach().cpu().numpy()\n",
        "                labels = torch.cat([x[\"labels\"] for x in output]).detach().cpu().numpy()\n",
        "                loss = torch.stack([x[\"loss\"] for x in output]).mean()\n",
        "                self.log(f\"val_loss_{split}\", loss, prog_bar=True)\n",
        "                split_metrics = {\n",
        "                    f\"{k}_{split}\": v for k, v in self.metric.compute(predictions=preds, references=labels).items()\n",
        "                }\n",
        "                self.log_dict(split_metrics, prog_bar=True)\n",
        "            self.validation_step_outputs.clear()\n",
        "            return\n",
        "\n",
        "        preds = torch.cat([x[\"preds\"] for x in self.validation_step_outputs]).detach().cpu().numpy()\n",
        "        labels = torch.cat([x[\"labels\"] for x in self.validation_step_outputs]).detach().cpu().numpy()\n",
        "        loss = torch.stack([x[\"loss\"] for x in self.validation_step_outputs]).mean()\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_metrics = self.metric.compute(predictions=preds, references=labels)\n",
        "        val_accuracy = val_metrics.get('accuracy', val_metrics.get('f1', 0.0))\n",
        "\n",
        "        # Update best validation accuracy\n",
        "        if val_accuracy > self.best_val_accuracy:\n",
        "            self.best_val_accuracy = val_accuracy\n",
        "\n",
        "        # Log validation metrics\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_accuracy\", val_accuracy, prog_bar=True)\n",
        "        self.log(\"best_val_accuracy\", self.best_val_accuracy, prog_bar=True)\n",
        "        self.log_dict(val_metrics, prog_bar=True)\n",
        "\n",
        "        self.validation_step_outputs.clear()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            optimizer_grouped_parameters,\n",
        "            lr=self.hparams.learning_rate,\n",
        "            eps=self.hparams.adam_epsilon\n",
        "        )\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=self.hparams.warmup_steps,\n",
        "            num_training_steps=self.trainer.estimated_stepping_batches,\n",
        "        )\n",
        "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
        "        return [optimizer], [scheduler]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSF3bkhFl4U5"
      },
      "outputs": [],
      "source": [
        "# Seed\n",
        "L.seed_everything(42)\n",
        "\n",
        "# Data and model\n",
        "dm = GLUEDataModule(\n",
        "    model_name_or_path=\"distilbert-base-uncased\",\n",
        "    task_name=\"mrpc\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    train_batch_size=train_batch_size,\n",
        "    eval_batch_size=eval_batch_size,\n",
        ")\n",
        "dm.setup(\"fit\")\n",
        "\n",
        "model = GLUETransformer(\n",
        "    model_name_or_path=\"distilbert-base-uncased\",\n",
        "    num_labels=dm.num_labels,\n",
        "    eval_splits=dm.eval_splits,\n",
        "    task_name=dm.task_name,\n",
        "    learning_rate=learning_rate,\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    adam_epsilon=adam_epsilon,\n",
        "    dropout_rate=dropout_rate,\n",
        "    train_batch_size=train_batch_size,\n",
        "    eval_batch_size=eval_batch_size,\n",
        ")\n",
        "\n",
        "# W&B run name with all hyperparameters\n",
        "run_name = (\n",
        "    f\"distilbert_lr{learning_rate}_wd{weight_decay}_\"\n",
        "    f\"warmup{warmup_steps}_eps{adam_epsilon}_\"\n",
        "    f\"dropout{dropout_rate}_maxseq{max_seq_length}_\"\n",
        "    f\"gradclip{gradient_clip_val}\"\n",
        ")\n",
        "\n",
        "# WandbLogger will automatically log model hyperparameters from save_hyperparameters()\n",
        "wandb_logger = WandbLogger(\n",
        "    project=\"HyperparameterTuning\",\n",
        "    name=run_name,\n",
        "    log_model=False,\n",
        ")\n",
        "\n",
        "# Trainer with gradient clipping\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=num_epochs,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    logger=wandb_logger,\n",
        "    gradient_clip_val=gradient_clip_val,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.fit(model, datamodule=dm)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
